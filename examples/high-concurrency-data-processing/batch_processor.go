package main

import (
	"fmt"
	"math/rand"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"github.com/xinjiayu/rxgo"
)

// BatchProcessor æ‰¹å¤„ç†å™¨
type BatchProcessor struct {
	batchSize   int
	parallelism int
}

// NewBatchProcessor åˆ›å»ºæ‰¹å¤„ç†å™¨
func NewBatchProcessor() *BatchProcessor {
	return &BatchProcessor{
		batchSize:   1000,
		parallelism: runtime.NumCPU(),
	}
}

// BatchItem æ‰¹å¤„ç†é¡¹
type BatchItem struct {
	ID       int     `json:"id"`
	Data     string  `json:"data"`
	Size     int     `json:"size"`
	Priority int     `json:"priority"`
	Value    float64 `json:"value"`
}

// BatchResult æ‰¹å¤„ç†ç»“æœ
type BatchResult struct {
	BatchID      int         `json:"batch_id"`
	ProcessedAt  time.Time   `json:"processed_at"`
	ItemCount    int         `json:"item_count"`
	TotalSize    int         `json:"total_size"`
	ProcessingMS int64       `json:"processing_ms"`
	WorkerID     int         `json:"worker_id"`
	Items        []BatchItem `json:"items"`
}

// RunExample è¿è¡Œæ‰¹å¤„ç†ç¤ºä¾‹
func (bp *BatchProcessor) RunExample() {
	fmt.Printf("ğŸ“¦ å¯åŠ¨æ‰¹å¤„ç†å™¨ (æ‰¹å¤§å°: %d, å¹¶è¡Œåº¦: %d)\n", bp.batchSize, bp.parallelism)

	// 1. ç”Ÿæˆå¤§é‡æ•°æ®
	totalItems := 50000
	items := bp.generateBatchItems(totalItems)
	fmt.Printf("ğŸ“‹ ç”Ÿæˆäº† %d ä¸ªå¾…å¤„ç†é¡¹\n", len(items))

	// 2. å°†æ•°æ®åˆ†æ‰¹
	batches := bp.createBatches(items)
	fmt.Printf("ğŸ“¦ åˆ›å»ºäº† %d ä¸ªæ‰¹æ¬¡\n", len(batches))

	// 3. å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
	start := time.Now()
	results := bp.processBatchesParallel(batches)
	duration := time.Since(start)

	fmt.Printf("âš¡ å¹¶è¡Œæ‰¹å¤„ç†å®Œæˆ: å¤„ç†äº† %d ä¸ªæ‰¹æ¬¡ï¼Œè€—æ—¶ %v\n", len(results), duration)

	// 4. ä¸²è¡Œå¤„ç†å¯¹æ¯”
	start = time.Now()
	serialResults := bp.processBatchesSerial(batches)
	serialDuration := time.Since(start)

	fmt.Printf("ğŸŒ ä¸²è¡Œæ‰¹å¤„ç†å®Œæˆ: å¤„ç†äº† %d ä¸ªæ‰¹æ¬¡ï¼Œè€—æ—¶ %v\n", len(serialResults), serialDuration)
	fmt.Printf("ğŸš€ æ€§èƒ½æå‡: %.2fx\n", float64(serialDuration)/float64(duration))

	// 5. åˆ†ææ‰¹å¤„ç†ç»“æœ
	bp.analyzeBatchResults(results)
}

// generateBatchItems ç”Ÿæˆæ‰¹å¤„ç†é¡¹
func (bp *BatchProcessor) generateBatchItems(count int) []BatchItem {
	items := make([]BatchItem, count)
	dataTemplates := []string{"ç”¨æˆ·æ•°æ®", "è®¢å•ä¿¡æ¯", "äº§å“è¯¦æƒ…", "æ—¥å¿—è®°å½•", "ç³»ç»Ÿäº‹ä»¶"}

	for i := 0; i < count; i++ {
		template := dataTemplates[rand.Intn(len(dataTemplates))]
		items[i] = BatchItem{
			ID:       i + 1,
			Data:     fmt.Sprintf("%s_%d", template, i),
			Size:     rand.Intn(1000) + 100,
			Priority: rand.Intn(5) + 1,
			Value:    rand.Float64() * 1000,
		}
	}

	return items
}

// createBatches åˆ›å»ºæ‰¹æ¬¡
func (bp *BatchProcessor) createBatches(items []BatchItem) [][]BatchItem {
	var batches [][]BatchItem

	for i := 0; i < len(items); i += bp.batchSize {
		end := i + bp.batchSize
		if end > len(items) {
			end = len(items)
		}
		batches = append(batches, items[i:end])
	}

	return batches
}

// processBatchesParallel å¹¶è¡Œå¤„ç†æ‰¹æ¬¡
func (bp *BatchProcessor) processBatchesParallel(batches [][]BatchItem) []BatchResult {
	var results []BatchResult
	var mu sync.Mutex
	var wg sync.WaitGroup
	var processedBatches int64

	// è½¬æ¢ä¸ºinterface{}åˆ‡ç‰‡
	batchInterfaces := make([]interface{}, len(batches))
	for i, batch := range batches {
		batchInterfaces[i] = batch
	}

	// åˆ›å»ºå¹¶è¡ŒFlowable
	parallelFlowable := rxgo.ParallelFromSlice(batchInterfaces, bp.parallelism).
		Map(func(v interface{}) (interface{}, error) {
			batch := v.([]BatchItem)
			batchID := int(atomic.AddInt64(&processedBatches, 1))
			workerID := (batchID - 1) % bp.parallelism

			processingStart := time.Now()

			// æ¨¡æ‹Ÿæ‰¹å¤„ç†é€»è¾‘
			processedBatch := bp.processSingleBatch(batchID, batch, workerID)

			processingDuration := time.Since(processingStart)
			processedBatch.ProcessingMS = processingDuration.Milliseconds()

			return processedBatch, nil
		}).
		Filter(func(v interface{}) bool {
			// å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ‰¹å¤„ç†ç»“æœçš„è¿‡æ»¤é€»è¾‘
			result := v.(BatchResult)
			return result.ItemCount > 0
		})

	// æ”¶é›†ç»“æœ
	subscriptions := parallelFlowable.SubscribeWithCallbacks(
		func(value interface{}) {
			result := value.(BatchResult)
			mu.Lock()
			results = append(results, result)
			mu.Unlock()
		},
		func(err error) {
			fmt.Printf("âŒ æ‰¹å¤„ç†é”™è¯¯: %v\n", err)
		},
		func() {
			wg.Done()
		},
	)

	wg.Add(len(subscriptions))

	// è¯·æ±‚æ‰€æœ‰æ•°æ®
	for _, subscription := range subscriptions {
		subscription.Request(int64(len(batches)))
	}

	wg.Wait()
	return results
}

// processBatchesSerial ä¸²è¡Œå¤„ç†æ‰¹æ¬¡
func (bp *BatchProcessor) processBatchesSerial(batches [][]BatchItem) []BatchResult {
	var results []BatchResult

	for i, batch := range batches {
		processingStart := time.Now()
		result := bp.processSingleBatch(i+1, batch, 0)
		result.ProcessingMS = time.Since(processingStart).Milliseconds()
		results = append(results, result)
	}

	return results
}

// processSingleBatch å¤„ç†å•ä¸ªæ‰¹æ¬¡
func (bp *BatchProcessor) processSingleBatch(batchID int, items []BatchItem, workerID int) BatchResult {
	// æ¨¡æ‹Ÿæ‰¹å¤„ç†æ“ä½œ
	var totalSize int
	processedItems := make([]BatchItem, len(items))

	for i, item := range items {
		// æ¨¡æ‹Ÿæ•°æ®å¤„ç†
		processedItem := item
		processedItem.Value = processedItem.Value * 1.1 // ç®€å•çš„å€¼è½¬æ¢

		processedItems[i] = processedItem
		totalSize += item.Size

		// æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
		time.Sleep(time.Microsecond * 10)
	}

	return BatchResult{
		BatchID:     batchID,
		ProcessedAt: time.Now(),
		ItemCount:   len(processedItems),
		TotalSize:   totalSize,
		WorkerID:    workerID,
		Items:       processedItems,
	}
}

// analyzeBatchResults åˆ†ææ‰¹å¤„ç†ç»“æœ
func (bp *BatchProcessor) analyzeBatchResults(results []BatchResult) {
	if len(results) == 0 {
		fmt.Println("âŒ æ²¡æœ‰æ‰¹å¤„ç†ç»“æœå¯åˆ†æ")
		return
	}

	fmt.Println("\nğŸ“ˆ æ‰¹å¤„ç†ç»“æœåˆ†æ:")

	// ç»Ÿè®¡ä¿¡æ¯
	var totalItems, totalSize int
	var totalProcessingTime int64
	workerStats := make(map[int]struct {
		batches     int
		items       int
		totalTimeMS int64
	})

	for _, result := range results {
		totalItems += result.ItemCount
		totalSize += result.TotalSize
		totalProcessingTime += result.ProcessingMS

		stats := workerStats[result.WorkerID]
		stats.batches++
		stats.items += result.ItemCount
		stats.totalTimeMS += result.ProcessingMS
		workerStats[result.WorkerID] = stats
	}

	// è¾“å‡ºæ€»ä½“ç»Ÿè®¡
	fmt.Printf("ğŸ“Š æ€»ä½“ç»Ÿè®¡:\n")
	fmt.Printf("   æ€»æ‰¹æ¬¡æ•°: %d\n", len(results))
	fmt.Printf("   æ€»é¡¹ç›®æ•°: %d\n", totalItems)
	fmt.Printf("   æ€»æ•°æ®å¤§å°: %d bytes\n", totalSize)
	fmt.Printf("   æ€»å¤„ç†æ—¶é—´: %d ms\n", totalProcessingTime)
	fmt.Printf("   å¹³å‡æ‰¹æ¬¡å¤„ç†æ—¶é—´: %.2f ms\n", float64(totalProcessingTime)/float64(len(results)))

	// è¾“å‡ºå·¥ä½œè€…ç»Ÿè®¡
	fmt.Printf("ğŸ”§ å·¥ä½œè€…ç»Ÿè®¡:\n")
	for workerID, stats := range workerStats {
		avgTimePerBatch := float64(stats.totalTimeMS) / float64(stats.batches)
		fmt.Printf("   Worker %d: %dæ‰¹æ¬¡, %dé¡¹ç›®, å¹³å‡%.2fms/æ‰¹æ¬¡\n",
			workerID, stats.batches, stats.items, avgTimePerBatch)
	}

	// è®¡ç®—ååé‡
	if totalProcessingTime > 0 {
		throughputPerSecond := float64(totalItems) / (float64(totalProcessingTime) / 1000.0)
		fmt.Printf("ğŸ“ˆ å¤„ç†ååé‡: %.2f é¡¹ç›®/ç§’\n", throughputPerSecond)
	}
}
